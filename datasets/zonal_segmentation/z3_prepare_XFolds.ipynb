{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b7047d",
   "metadata": {},
   "source": [
    "### Preparing CFV splits for\n",
    " Retrieve available data on the disk and validate it\n",
    "* Match data table with it\n",
    "* Write file names to the table\n",
    "* Split table into N-cross splits + separate split for test\n",
    "* Use table as CSV Dataset to retrieve the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f589d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys; sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "test_split = True\n",
    "\n",
    "dataset_source = \"/home/oleksii/projects/ohif-orthanc-postgres-docker/datasets/zonal_segmentation/zone_dataset_2512_20240821.csv\"\n",
    "df = pd.read_csv(dataset_source, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f37e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_and_basename(path):\n",
    "\n",
    "    # Split the path into directory and file name\n",
    "    directory, file_name = os.path.split(path)\n",
    "    # Get the last directory name\n",
    "    last_directory = os.path.basename(directory)\n",
    "    # Combine the last directory name and the file name\n",
    "    result = os.path.join(last_directory, file_name)\n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c8ffbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alta_dataset(data_path):\n",
    "    studies = os.listdir(data_path)\n",
    "    records = []\n",
    "    for study_id in studies:\n",
    "        \n",
    "        study_path = os.path.join(data_path, study_id)\n",
    "        t2ws = glob.glob(os.path.join(study_path, \"*tra_t2w.nrrd\"))\n",
    "        adcs = glob.glob(os.path.join(study_path, \"*tra_adc.nrrd\"))\n",
    "        segs = glob.glob(os.path.join(study_path, \"*.seg.nrrd\"))\n",
    "        \n",
    "        d = {}\n",
    "        d['study_orthanc_id'] = study_id\n",
    "        d[\"t2w\"] = get_dir_and_basename(t2ws[0]) if t2ws else None  \n",
    "        d[\"adc\"] = get_dir_and_basename(adcs[0]) if adcs else None  \n",
    "        d[\"seg\"] = get_dir_and_basename(segs[0]) if segs else None  \n",
    "        records.append(d)\n",
    "         \n",
    "    ds = pd.DataFrame(records)\n",
    "    print(len(ds))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ebf91ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501\n",
      "2501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = \"/data/oleksii/Prostate-ZONE-Datasets-NRRDS/ALTA-Zone-Dataset-multimodal-preprocessed\"\n",
    "dataset_alta = get_alta_dataset(data_path)\n",
    "\n",
    "# keep full cases\n",
    "dataset_alta = dataset_alta[(~dataset_alta['t2w'].isnull()) & (~dataset_alta['adc'].isnull()) & (~dataset_alta['seg'].isnull())]\n",
    "print(len(dataset_alta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e19b526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge preprocessed data with tabular one \n",
    "dataset_alta_m = pd.merge(dataset_alta, df, how=\"inner\", on=\"study_orthanc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f91460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving fold 0\n",
      "Saving fold 1\n",
      "Saving fold 2\n",
      "Saving fold 3\n",
      "Saving fold 4\n"
     ]
    }
   ],
   "source": [
    "# recreate the old split but with correct ids\n",
    "dataset1260 = pd.read_csv(\"/home/oleksii/projects/ohif-orthanc-postgres-docker/datasets/zonal_segmentation/zone_dataset_1260_20240129.csv\", sep=\";\")\n",
    "\n",
    "test_split = \"/home/oleksii/projects/prostate-cad/data_loading/zonal_datasets/ALTA-Zone-Dataset/test.csv\"\n",
    "df_test = pd.read_csv(test_split, sep=';')\n",
    "test_case_ids = df_test['t2w'].str.split('/').str[-2].to_list()\n",
    "\n",
    "splits_path = \"/home/oleksii/projects/ohif-orthanc-postgres-docker/datasets/zonal_segmentation/cross_fold_splits_20230926\"\n",
    "os.makedirs(splits_path, exist_ok=True)\n",
    "\n",
    "dataset1260_test = dataset1260[dataset1260['t2w_series_oid'].isin(test_case_ids)]\n",
    "dataset1260_test = dataset_alta_m[dataset_alta_m['study_orthanc_id'].isin(dataset1260_test['study_orthanc_id'])]\n",
    "dataset1260_test.to_csv(os.path.join(splits_path, 'test.csv'), sep=';', index=False)\n",
    "\n",
    "for fold in range(0, 5):\n",
    "    fold_path = f\"/home/oleksii/projects/prostate-cad/data_loading/zonal_datasets/ALTA-Zone-Dataset/fold_{fold}\"\n",
    "    \n",
    "    df_valid = pd.read_csv(os.path.join(fold_path, \"valid.csv\"), sep=';')\n",
    "    df_valid['t2w_series_oid'] = df_valid['t2w'].str.split('/').str[-2].to_list()\n",
    "    \n",
    "    df_train = pd.read_csv(os.path.join(fold_path, \"train.csv\"), sep=';')\n",
    "    df_train['t2w_series_oid'] = df_train['t2w'].str.split('/').str[-2].to_list()\n",
    "    \n",
    "    dataset1260_valid = dataset1260[dataset1260['t2w_series_oid'].isin(df_valid['t2w_series_oid'])]\n",
    "    dataset1260_train = dataset1260[dataset1260['t2w_series_oid'].isin(df_train['t2w_series_oid'])]\n",
    "\n",
    "    dataset1260_train = dataset_alta_m[dataset_alta_m['study_orthanc_id'].isin(dataset1260_train['study_orthanc_id'])]\n",
    "    dataset1260_valid = dataset_alta_m[dataset_alta_m['study_orthanc_id'].isin(dataset1260_valid['study_orthanc_id'])]\n",
    "\n",
    "    \n",
    "    print(f\"Saving fold {fold}\")\n",
    "    \n",
    "    fold_path = os.path.join(splits_path, f'fold_{fold}')\n",
    "    os.makedirs(fold_path, exist_ok=True)\n",
    "\n",
    "    dataset1260_train.to_csv(os.path.join(fold_path, 'train.csv'), sep=';', index=False)\n",
    "    dataset1260_valid.to_csv(os.path.join(fold_path, 'valid.csv'), sep=';', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3aa4b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_orthanc_id</th>\n",
       "      <th>t2w</th>\n",
       "      <th>adc</th>\n",
       "      <th>seg</th>\n",
       "      <th>study_date</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>t2w_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [study_orthanc_id, t2w, adc, seg, study_date, patient_id, StudyInstanceUID, t2w_ids]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_alta_m[dataset_alta_m['patient_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get the test set\n",
    "# sgkfold = KFold(n_splits=nfolds + 1, shuffle=True, random_state=42)\n",
    "# splits = list(sgkfold.split(X=dataset_alta_m))\n",
    "# first, get the stratified test set\n",
    "# sgkfold = GroupKFold(n_splits=nfolds + 1)\n",
    "# splits = list(sgkfold.split(X=dataset_alta_m, groups=dataset_alta_m['patient_id'].to_list()))\n",
    "\n",
    "# # split test from train! \n",
    "# dataset_test = dataset_alta_m.iloc[splits[0][1]]\n",
    "# dataset_train = dataset_alta_m.iloc[splits[0][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ae72eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8030cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = \"/home/oleksii/projects/ohif-orthanc-postgres-docker/datasets/zonal_segmentation/cross_fold_splits_20240925\"\n",
    "os.makedirs(splits_path, exist_ok=True)\n",
    "\n",
    "# len(dataset_test)\n",
    "dataset1260_test.to_csv(os.path.join(splits_path, 'test.csv'), sep=';', index=False)\n",
    "\n",
    "dataset_train = dataset_alta_m[~dataset_alta_m['study_orthanc_id'].isin(dataset1260_test['study_orthanc_id'])]\n",
    "# next, get the cross fold set\n",
    "sgkfold_train = GroupKFold(n_splits=nfolds)\n",
    "splits_folds = list(sgkfold_train.split(X=dataset_train, groups=dataset_train['patient_id'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52da54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving fold 0\n",
      "Saving fold 1\n",
      "Saving fold 2\n",
      "Saving fold 3\n",
      "Saving fold 4\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(os.path.join(splits_path, os.path.basename(dataset_source)), sep=';', index=False) \n",
    "\n",
    "for i, split in enumerate(splits_folds):\n",
    "    print(f\"Saving fold {i}\")\n",
    "    \n",
    "    fold_path = os.path.join(splits_path, f'fold_{i}')\n",
    "    os.makedirs(fold_path, exist_ok=True)\n",
    "    \n",
    "    train_fold = dataset_train.iloc[split[0]]\n",
    "    valid_fold = dataset_train.iloc[split[1]]\n",
    "    train_fold.to_csv(os.path.join(fold_path, 'train.csv'), sep=';', index=False)\n",
    "    valid_fold.to_csv(os.path.join(fold_path, 'valid.csv'), sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a931b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
